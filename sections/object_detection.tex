\begin{document}
\section{Brief introduction to Neurons and Networks}
Similar to the neurons in the human brain, neurons in computer science are approaching the same concept and same ideology.\\
The functionality of a neuron is to retrieve data, possibly and ideally multiple at the same time, process and output a single result. There
are many types of neurons, for introduction purposes I am just gonna mention two here.
\begin{itemize}
    \item Perceptrons
    \item Sigmoids
\end{itemize}
The more commonly used artificial neuron in Neural Network models is the Sigmoid. The reasons for that will be mentioned in the chapters
belowe.

\subsection{Percpetrons}
Perceptrons were developed in 1950 to 1960 by the scientist Frank Rosenblatt, inspired by earlier works from Waren McCulloch and Walter Pitts.
\begin{center}
    \includegraphics[scale=0.5]{images/simple_neuron.png}
\end{center}
In this example our neuron has 2 input variables and one output, in theory it can have more or less. Further more Frank Rosenblatt proposes
the concept of weights for each input variable defining how important a variable is compared to another.\\
\vspace{0.5cm}
    \begin{equation*}
        output=
        \begin{cases}
            0 \text{ if } \sum{_j}{w_jx_j \le threshold}\\
            1 \text{ if } \sum{_j}{w_jx_j > threshold}
        \end{cases}
    \end{equation*}
\vspace{0.5cm}
A single neuron is by no means comparable to a decision making possibilities of a human being, but it can weigh variables and make decisions
accordingly by defining a threshold for when a true or false gets output. Another way to create a conditional behavior is to use a bias
instead of a threshold.
\begin{center}
    \includegraphics[scale=0.5]{images/simple_neuron_bias.png}
\end{center}
\vspace{0.5cm}
    \begin{equation*}
        output=
        \begin{cases}
            0 \text{ if } \sum{_j}{w_jx_j+b \le 0}\\
            1 \text{ if } \sum{_j}{w_jx_j+b > 0}
        \end{cases}
    \end{equation*}
\vspace{0.5cm} \\
Making it obvious that they are able to perform more complex decisions in layers.
\begin{center}
    \includegraphics[scale=0.5]{images/neural_network.png}
\end{center}
\newpage
\noindent
The columns in this network are called layers, the first column is refered to as the first layers and the last one as the output one all the
ones in between are called hidden layers. \\
Since the result of a perceptron can only be one or zero (true or false), one major problem someone faces when using perceptrons in more
complex neural networks is that biases and weights can have weird and unwanted effects. Making perceptrons trigger where they should not,
thats where sigmoids come in handy and build on top of the concept of perceptrons.

\subsection{Sigmoids}
The core principle of a sigmoid neuron is the same as the perceptrons. Just like perceptrons, sigmoids have input and output variables but
instead of just being 0 or 1 it can be anything in between 0 and 1 so 0.5234 is a valid output of a sigmoid.
\begin{center}
    \includegraphics[scale=0.5]{images/simple_neuron.png}
\end{center}
It can also have weights and biases similiar to the perceptron:
\begin{center}
    \includegraphics[scale=0.5]{images/simple_neuron_bias.png}
\end{center}
The arithmetic function on the other looks different and is called the sigmoid function or sometimes the logistic function.
\vspace{0.5cm}
\begin{equation*}
    \begin{split}
        \sigma(z) & = \frac{1}{1+e^{-z}}
    \end{split}
\end{equation*}
\vspace{0.5cm}
To put it more explicit with input variables, weights and bias:
\vspace{0.5cm}
\begin{equation*}
    \begin{split}
        \frac{1}{1+exp(-\sum{_j}{w_jx_j-b})}
    \end{split}
\end{equation*}
Since the algebraic form of {$\sigma$} a is smoothed and not a step function this difference is minimal but makes a huge difference in the
way how weights and bias influence the result of a sigmoid compared to a percpetron.
\vspace{0.5cm}
\begin{center}
    \begin{tikzpicture}
        \begin{axis}[
                width=0.8\textwidth,
                height=0.4\textwidth,
                axis x line=bottom,
                xmin=-4,
                xmax=4,
                xlabel near ticks,
                axis y line=left,
                ymin=0,
                ymax=1,
                ylabel near ticks
            ]
            \addplot[color=red, domain=-4:4, width=2] (x,{1/(1+exp(-x))});
        \end{axis}
    \end{tikzpicture}
\end{center}
\vspace{0.5cm}
\begin{center}
    \begin{tikzpicture}
        \begin{axis}[
                width=0.8\textwidth,
                height=0.4\textwidth,
                axis x line=bottom,
                xmin=-4,
                xmax=4,
                xlabel near ticks,
                axis y line=left,
                ymin=0,
                ymax=1,
                ylabel near ticks
            ]
            \addplot[color=red, width=2] coordinates {
                    (-4,0)
                    (0,0)
                    (0,1)
                    (4,1)
            };
        \end{axis}
    \end{tikzpicture}
\end{center}

\newpage

\section{Current state}
Object Detection in dealing with two major problems and therefore can be split into two processes, these are object localization and object
classification of multiple objects in one image. There are many approaches in current Neural Network models to perform these actions.
There are models which have a multi layer architecture, each performing complex tasks such as analyzing, localizing and classifying each
sections individually, making the cost high and the network in general slow but accurate.
There models that combine functionality in one layer so that one layer for instance localizes and classifies at the same time, is making the
model more flexible, smaller and therefore faster but less accurate.
The trade off between accuracy and speed is something that all networks deal with nowadays especially if the goal is to have a near real life object
detection system which is still reliable and accurate when doing so. \\
There are multiple algorithms covering various forms of this formula, called RCNN, F-RCNN, SSD, YOLO but first we will cover the approach of
detecting interesting regions in an image because this is a key problem in object detection.

\subsection{Approaches to Object Localization}
The segmentation of an image is the key approach to Object Localization, since images are always hierarchical the segmentation as well has
to be hierarchical. It has to be able to cover different criteria and forms, where maybe objects are part of a bigger total or just single
parts inside another one. Since is not feasible to compute every possibility inside an image there has to be some kind of separation
through grids and scales. \\
As there are many approaches to algorithms how to analyze and classify regions, there are many approaches for algorithms to detect
interesting sections of an image which may contain objects.

\subsubsection{Exhaustive Search}
Since an object can be located anywhere in an image the scope to look for it is enormous making the computational cost for such search very
expensive. To compensate for this cost most exhaustive search approaches such as the sliding window approach, constraint the size and aspect
ratio of the window over the grid, also using weak classifiers and economic image features such as histogram of oriented gradients
(HOG).\cite{selectivesearch} \\
HOG approaches the problem of recognizing and detecting objects in an unknown image through detecting corners. It analyzes the distribution and their
orientation through which he is able to separate the image in multiple partitions or detect similar regions in different images.
Robert K. McConnell described the concept in a patent in 1986 but it became known in 2005 through a publication of Navneet Dalal and Bill
Triggs.\cite{wiki_hog}
\vspace{0.5cm}
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/Dlib_Learned-HOG-Detector.jpg} \cite{wiki_hog}
\end{center}

\subsubsection{Selective Search}
A selective search algorithm is subjected into 3 design ideas:
\begin{itemize}
    \item Capture All Scales \\ \\
        The idea is similar to the one of the Exhaustive Search that all objects have to be found. Therefore all scales have to be
        considered as a potential region. The best approach is a hierarchical grouping, where a initial sub segmentation has to
        be performed. \cite{selectivesearch}
        \begin{center}
            \includegraphics[width=0.5\textwidth]{images/breakfast_fnh.jpg}\cite{sssegmentationc}
        \end{center}
        After the segmentation a grouping of regions is done by similarity. After each grouping a similarity between
        resulting regions and its neighbors are being calculated. This process is done until the whole image becomes a single region.\cite{selectivesearch}
        \begin{center}
            \includegraphics[width=0.5\textwidth]{images/breakfast-top-200-proposals.jpg}\cite{sssegmentationbb}
        \end{center}
    \item Diversification \\ \\
        There is no single strategy for grouping regions together therefore multiple aspects have to be considered. Selective search
        diversifies by using a variety of color spaces with different invariance properties, by using different similarity measures and by
        varying the starting regions.  By using different color spaces, selective search is able to account for different scene and light
        conditions. To account for these variances selective search is performing the hierarchical grouping algorithm with different color
        spaces which have different invariance properties.
    \item Fast to Compute \\ \\
        The fast computation is being achieved by four complementary similarity measures. All these measures are in range of [0, 1] which
        facilitates combinations of these measures. \cite{selectivesearch}
        \begin{itemize}
            \item \large{S}\emph{color} \\ \\
                Measures color similarity specifically for each region where a color histogram of 25 bins is being created and normalized
                with the L1 norm. Similarity is measured using the histogram intersection: \cite{selectivesearch} \\
                \begin{center}
                    \begin{equation*}
                        S_{color}(r_i,r_j) = \sum_{n=1}^{n} min(c_i^{k},c_j^{k})
                    \end{equation*}\cite{selectivesearch}
                \end{center}
                \newpage
                \noindent
                The histogram can be efficienlty propagated through the hierarchy by: \\
                \begin{center}
                    \begin{equation*}
                        \begin{split}
                            C_t & = \frac{size(r_j)*C_i+size(r_j)*C_j}{size(r_i)+size(r_j)}
                        \end{split}
                    \end{equation*}\cite{selectivesearch}
                \end{center}

            \item \large{S}\emph{texture} \\ \\
                Selective Search measures texture similarity through the usage of the SIFT algorithm. SIFT stands for scale invariant
                feature transform and is a algorithm to detect and describe features in a region. Further more it takes Gaussian derivatives
                in eight orientations for each color channel, where a 10 bin histogram is being extracted. Similarity is being measured
                again using the histogram intersections and the propagation is function is the same as for the color. \cite{selectivesearch}
                \begin{center}
                    \begin{equation*}
                        S_{texture}(r_i,r_j) = \sum_{n=1}^{n} min(t_i^{k},t_j^{k})
                    \end{equation*}\cite{selectivesearch}
                \end{center}

            \item \large{S}\emph{size} \\ \\

            \item \large{S}\emph{fill}
        \end{itemize}
\end{itemize}

\subsubsection{Region Proposal Network}

\subsection{Approaches to Object Classification}

\end{document}     
