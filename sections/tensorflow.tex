% Write about tensorflow 
    %   - short background on tensorflow
    %   - ways of training/ new architecture (code or config), new model existing layout , transfer learning
    %   - setup for training (cpu, gpu, cuda, cudnn)
    %   - short background on cuda and cudnn
    %   - training a model
    %   - analysis of model
\begin{document}
TensorFlow™ is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment
of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices.
Originally developed by researchers and engineers from the Google Brain team within Google’s AI organization, it comes with strong support
for machine learning and deep learning and the flexible numerical computation core is used across many other scientific
domains.\cite{tensorflow}

\section{Writing Object Detection Models with Tensorflow}\label{train-with-tensorflow}
Tensorflow is a full fledged machine learning library which supports the programming languages C++, Python. It is a multi purpose library
which can be used for training Neural Networks for Image Recognition, object detection or other purposes. Furthermore Tensorflow uses
Keras which is a high level API for building and training deep learning models. In object detection which I am using Tensorflow in this
report for, you are able to write a object detection system in multiple ways.
\begin{itemize}
    \item Do it Yourself \\ \\
        You are able to write your object detection logic from scratch, starting at how features are being extracted processed and
        evaluated. How layers of your neural networks are connected, sequenced, communicate and how the object localization and object
        classification is being used and implemented.
    \item Just write the Model \\ \\
        Tensorflows object detection model which they provide at \url{https://github.com/tensorflow/models} is a simple yet effective way of
        training object detection Neural Netowrks. You are able to compose new ideas for models with simple '.config' files without going
        too deep into the code and logic of Tensorflow. These configuration files contain the setup of the neural network model. Such as in
        which sequence the layers are going to be, what the IoU value should be for a bounding box to be valid and which features have to
        be extracted by the Tensorflow API, this obviously are just a hand full of the features Tensorflow provides with this Library.
        You can see a full configuration file used for training in the appendix.
\end{itemize}

\section{Training Models with Tensorflow}\label{models-with-tensorflow}
As there are multiple ways of setting up your object detection system, if you are going with the ''Just write the Model'' approach, there
are also a couple of ways training the model.
\begin{itemize}
    \item Train from Scratch \\ \\
        Which ever way you are training your model, starting from scratch without a basis will require: \\
        {- a lot of resources (images, ground truth data)} \\
        {- a lot of training time} \\
    \item Train by transfer Learning \\ \\
        When you are doing transfer learning, you are taking an already trained model and build on top of it with your own image set.\\
        This results in: \\
        {- far fewer images needed} \\
        {- less training time (comparing days and weeks to hours and minutes)} \\
\end{itemize}
Training is pretty straight forward when using the setup from Tensorflow as mentioned in\ref{train-with-tensorflow} "Just write the Model".
For this you have to install Tensorflow and all the required dependencies. They can be found here:
\url{https://www.tensorflow.org/install/pip}. Further more some custom scripts were written to enable converting text files to ''.csv''
files, create   Further more some custom scripts were written to enable converting text files to ''.csv''
files to enable the generation of .record files and to merge entries of multiple files with the same naming (there were multiple files with
the same name and content but labeled differently for each category). Lastly environmental variables, proto
files and '.record' files had to be setup and compiled for Tensorflow.
\begin{center}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        Model & Speed(ms) &  mAP[{\textasciicircum}1] \\ \hline
        faster-rcnn-inception-v2-cooc & 58 & 28 \\ \hline
        ssd-mobilenet-v2-coco & 32 & 22 \\ \hline
    \end{tabular}
\end{center}
\section{Training results}
After setting up the environment my first attempt was getting the data myself, labeling them with the Open Source software
\href{https://github.com/tzutalin/labelImg}{LabelImg} and training a new Model through a Tensorflow configuration. This was a tedious effort and
resulted in a bad model which detected images pretty well as long as they were from the train set or similar but failed on real world data.
This was done with various combinations of data quantities which was not enough at all for this, IoU, variable and feature tweaks provided
through Tensorflow without much difference in its performance. To note is that these were my first attempts training models with Tensorflow
and I did not understand the whole procedure too well, meaning I didn't consult Tensorboard which is User Interface from Tensorflow to view
the results of my Data and Model. \\ 
After this I switched to transfer learning which takes the weights and knowledge of a already
\href{https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md}{existing models} from
Tensorflow and applies it to a different one with related problems. \\ 
Firstly I downloaded images and bounding box data through the API of ms coco which is a dataset providing more then 2.5 million label
instances in 328 thousand images.\cite{mscoco} There are other datasets such as Pascal VOC and ImageNet but none of them provided a easy way to
download data similar to MSCOCO. For the following models I downloaded 9 Classes with one thousand images and labels each to test, vary and experiment
with the amount of data provided to training my model. \\
Secondly I downloaded two models from Tensorflow, one was the faster-rcnn-inception-v2-coco and the ssd-mobilnet-v2-coco trained with the
dataset from MSCOCO. These are 2 models where the first one is implemented with the Faster-RCNN and the later with SSD algorithm. \\
When transfer learning I noticed that 200 images for each category was more then enough to get decent results, the results degraded compared
to the original Tensorflow models I used for transfer learning but it was still better then the initial attempts of training. The following
graphs are smoothed by a factor of 0.6. \\ \\
\begin{figure}[hbt!]
    \begin{center}
        \caption{mAP}
        \subfigure[mAP per Stage]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-map.png}}
        \subfigure[mAP @0.5 IoU]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-map@0-50iou.png}}
        \subfigure[mAP @0.75 IoU]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-map@0-75iou.png}}
    \end{center}
\end{figure}
\newpage \noindent
Even though the mAP is increasing over the duration of the training session you can see that it is not really increasing in performance but
overfiting through the following graphs
\begin{figure}[hbt!]
    \begin{center}
        \caption{Loss of Models}
        \subfigure[Box Classifier Loss]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-classification_loss.png}}
        \subfigure[Box Classifier Localization Loss]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-box_localization_loss.png}}
        \subfigure[RPN Localization Loss]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-rpn_localization_loss.png}}
        \subfigure[RPN Objectness Loss]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-rpn_objectness_loss.png}}
        \subfigure[Total Loss]{\includegraphics[width=0.45\textwidth]{images/tensorflow/frcnn-total_loss.png}}
    \end{center}
\end{figure}
\end{document}
